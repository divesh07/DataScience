{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demovid4_Stopword Removal.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPYjnrBNhg+l1NJFPj90fyJ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0do-Z5KBkG4m"},"source":["!pip install -U -q PyDrive\r\n","from pydrive.auth import GoogleAuth\r\n","from pydrive.drive import GoogleDrive\r\n","from google.colab import auth\r\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"amDYixfwkS8D"},"source":["auth.authenticate_user()\r\n","gauth = GoogleAuth()\r\n","gauth.credentials = GoogleCredentials.get_application_default()\r\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fXySCyVclXrn"},"source":["# Stopwords-Removal\r\n","* Get list of commonly used stop words from NLTK library\r\n","* Remove commonly used stop words from text documents\r\n","* Remove custom stop words from text documents"]},{"cell_type":"code","metadata":{"id":"rDKCEaREkqVE"},"source":["import re, nltk, pandas as pd, numpy as np\r\n","from nltk.tokenize import RegexpTokenizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ylbpprokqcg","executionInfo":{"status":"ok","timestamp":1611126065401,"user_tz":-330,"elapsed":2243,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"37b8ef4b-e0a5-4d25-89f9-544dcae4e55b"},"source":["nltk.download('stopwords')\r\n","nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"t1GDfCWmmahw"},"source":["***Common stopwords from nltk***\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gH8qOsyHmN23","executionInfo":{"status":"ok","timestamp":1611126267844,"user_tz":-330,"elapsed":1093,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"af28bc48-6a5d-4dfa-aaf0-8a63c0d0e78c"},"source":["stopwords = nltk.corpus.stopwords.words('english')\r\n","stopwords[:50]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be']"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcDJv-irmN6H","executionInfo":{"status":"ok","timestamp":1611126286273,"user_tz":-330,"elapsed":1123,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"84604f7e-54ca-4e95-e74f-053f45d377a9"},"source":["len(stopwords)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["179"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"Amq1WxBgmOPe"},"source":["tokenizer = RegexpTokenizer('\\w+')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PFvAKPkn7WC","executionInfo":{"status":"ok","timestamp":1611126656363,"user_tz":-330,"elapsed":1035,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"e2b1f70d-a742-4324-8d06-2380f38329c6"},"source":["doc = 'I visited my grandparents last week; We had a good time together'\r\n","tokens = tokenizer.tokenize(doc.lower())\r\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'visited',\n"," 'my',\n"," 'grandparents',\n"," 'last',\n"," 'week',\n"," 'we',\n"," 'had',\n"," 'a',\n"," 'good',\n"," 'time',\n"," 'together']"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3r3jI_-an7Zh","executionInfo":{"status":"ok","timestamp":1611126852663,"user_tz":-330,"elapsed":1017,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"7eaa5650-f25c-4ecd-f983-0cb4b473063d"},"source":["stop_list = [x for x in tokens if x not in stopwords]\r\n","stop_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['visited', 'grandparents', 'last', 'week', 'good', 'time', 'together']"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"BjKpMxQSpWp2"},"source":["All the common words got ignored and only important words are considered"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XXTWHffmpmLH","executionInfo":{"status":"ok","timestamp":1611127386469,"user_tz":-330,"elapsed":1022,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"56ba66f8-e0de-4524-9a5e-056e719ca331"},"source":["docs = ['I visited my grandparents last week; We had a good time together', 'nlp engineers spend most of their time on text cleaning'] # list of lists\r\n","\r\n","doc_list = []\r\n","\r\n","for x in docs:\r\n","  toks = tokenizer.tokenize(x.lower())\r\n","  stops = [y for y in toks if y not in stopwords] \r\n","  doc_list.append(stops)\r\n","doc_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['visited', 'grandparents', 'last', 'week', 'good', 'time', 'together'],\n"," ['nlp', 'engineers', 'spend', 'time', 'text', 'cleaning']]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"FYC8zLadrg36"},"source":["Here we got a list of lists with imp words only "]},{"cell_type":"markdown","metadata":{"id":"wy4DYJhcr34N"},"source":["### Combine elements in a single string"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yKnbkl60pmZP","executionInfo":{"status":"ok","timestamp":1611127777534,"user_tz":-330,"elapsed":1246,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"3524e7fd-02d3-4a0d-d4e8-1567e09d3f50"},"source":["docs = ['I visited my grandparents last week; We had a good time together', 'nlp engineers spend most of their time on text cleaning'] # list of lists\r\n","\r\n","docs_list = []\r\n","\r\n","for x in docs:\r\n","  toks1 = tokenizer.tokenize(x.lower())\r\n","  stops = [y for y in toks1 if y not in stopwords] \r\n","  docs_list.append(' '.join(stops)) # joined the tokens in a single doc with space\r\n","docs_list"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['visited grandparents last week good time together',\n"," 'nlp engineers spend time text cleaning']"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"H-XjbMZetFq0"},"source":["* All the tokens got combined as a single string\r\n","* Can also be seen as combined and cleaned doc"]},{"cell_type":"markdown","metadata":{"id":"ByYsc1bvtmId"},"source":["# Removing stopwords from text column"]},{"cell_type":"code","metadata":{"id":"I57OV23UpmgO"},"source":["downloaded = drive.CreateFile({'id':'12CUjW29tTTxYAcPhxuKb_qSn0UTzc4BR'}) # replace the id with id of file you want to access\r\n","downloaded.GetContentFile('imdb_sentiment.csv') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"r7hbYf_Mpmjm","executionInfo":{"status":"ok","timestamp":1611128118239,"user_tz":-330,"elapsed":1046,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"8aeacdab-dd50-4bae-fedb-79e6c05f2c3e"},"source":["data = pd.read_csv('imdb_sentiment.csv')\r\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A very, very, very slow-moving, aimless movie ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Not sure who was more lost - the flat characte...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Attempting artiness with black &amp; white and cle...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Very little music or anything to speak of.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The best scene in the movie was when Gerardo i...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  A very, very, very slow-moving, aimless movie ...          0\n","1  Not sure who was more lost - the flat characte...          0\n","2  Attempting artiness with black & white and cle...          0\n","3       Very little music or anything to speak of.            0\n","4  The best scene in the movie was when Gerardo i...          1"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBsN9n_AkXnw","executionInfo":{"status":"ok","timestamp":1611128320991,"user_tz":-330,"elapsed":1022,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"f2ccea74-67b8-4ee7-d8e1-4bd4f52131cb"},"source":["doc_list2 = []\r\n","\r\n","for x in data['review']:\r\n","  toks = tokenizer.tokenize(x.lower())\r\n","  stops = [y for y in toks if y not in stopwords]\r\n","  doc_list2.append(' '.join(stops))\r\n","doc_list2[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['slow moving aimless movie distressed drifting young man',\n"," 'sure lost flat characters audience nearly half walked',\n"," 'attempting artiness black white clever camera angles movie disappointed became even ridiculous acting poor plot lines almost non existent',\n"," 'little music anything speak',\n"," 'best scene movie gerardo trying find song keeps running head',\n"," 'rest movie lacks art charm meaning emptiness works guess empty',\n"," 'wasted two hours',\n"," 'saw movie today thought good effort good messages kids',\n"," 'bit predictable',\n"," 'loved casting jimmy buffet science teacher']"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"0lbcOUfEzvAG"},"source":["# Removing custom stopwords\r\n","* Apart from standard stopwords of 179 words, we can include custom stopwords in the list.   \r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cu_0S7kXuurk","executionInfo":{"status":"ok","timestamp":1611130193063,"user_tz":-330,"elapsed":1083,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"3ed815fb-b60a-49b0-b350-d789aa934ce5"},"source":["custom_stopwords = ['movie', 'little']\r\n","all_stopwords = np.hstack([stopwords, custom_stopwords])  #using fn horizontal stack to join two lists into a single list\r\n","\r\n","doc_list3 = []\r\n","print(len(all_stopwords))\r\n","for x in data['review']:\r\n","  toks = tokenizer.tokenize(x.lower())\r\n","  stops = [y for y in toks if y not in all_stopwords]\r\n","  doc_list3.append(' '.join(stops))\r\n","\r\n","doc_list3[:10]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["181\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['slow moving aimless distressed drifting young man',\n"," 'sure lost flat characters audience nearly half walked',\n"," 'attempting artiness black white clever camera angles disappointed became even ridiculous acting poor plot lines almost non existent',\n"," 'music anything speak',\n"," 'best scene gerardo trying find song keeps running head',\n"," 'rest lacks art charm meaning emptiness works guess empty',\n"," 'wasted two hours',\n"," 'saw today thought good effort good messages kids',\n"," 'bit predictable',\n"," 'loved casting jimmy buffet science teacher']"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"xbzMVJp41ped"},"source":[""],"execution_count":null,"outputs":[]}]}