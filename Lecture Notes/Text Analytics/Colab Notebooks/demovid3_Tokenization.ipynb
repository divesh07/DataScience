{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"demovid3_Tokenization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMwWems4vTDf0kqXSWWaUPb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8QXQuiNwb9Tr"},"source":["import pandas as pd, spacy, nltk, re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEirLWgDzQm5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611042924173,"user_tz":-330,"elapsed":5562,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"ec61472b-a9d5-439f-eaaa-5debb835d59f"},"source":["nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"8JDiiFTZ3psb"},"source":["doc = 'I visited my grandparents last week; We had a good time together'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V_6hHMe8M5II"},"source":["# Manual Process\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZJeKzCJ351Q","executionInfo":{"status":"ok","timestamp":1611042924176,"user_tz":-330,"elapsed":5548,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"47e3985a-e98b-477e-eb8d-b918e063722f"},"source":["# use lower and split the doc\r\n","tokens = doc.lower().split()\r\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'visited',\n"," 'my',\n"," 'grandparents',\n"," 'last',\n"," 'week;',\n"," 'we',\n"," 'had',\n"," 'a',\n"," 'good',\n"," 'time',\n"," 'together']"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"EJWxRoGi4Fbk","executionInfo":{"status":"ok","timestamp":1611042924178,"user_tz":-330,"elapsed":5534,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"a90aeb72-aed4-4581-c5bc-ad462d1ad3ab"},"source":["# Remove characters\r\n","doc_cleaned = re.sub('[^\\w\\s]','',doc.lower()) # removing semi-colon\r\n","doc_cleaned"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'i visited my grandparents last week we had a good time together'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPKs5sIL4nU0","executionInfo":{"status":"ok","timestamp":1611042924179,"user_tz":-330,"elapsed":5523,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"7f314791-734d-400d-8b4e-3cfb5f42e48d"},"source":["# split the cleaned doc \r\n","tokens = doc_cleaned.split(' ')\r\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'visited',\n"," 'my',\n"," 'grandparents',\n"," 'last',\n"," 'week',\n"," 'we',\n"," 'had',\n"," 'a',\n"," 'good',\n"," 'time',\n"," 'together']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"BOYF76sxNK7O"},"source":["# Automated process of tokenization"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tWAuh6FrMmtL","executionInfo":{"status":"ok","timestamp":1611042924182,"user_tz":-330,"elapsed":5516,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"c679c943-5063-4662-c3b7-dc7e0a7f5e25"},"source":["from nltk.tokenize import word_tokenize\r\n","tokens = word_tokenize(doc.lower())\r\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'visited',\n"," 'my',\n"," 'grandparents',\n"," 'last',\n"," 'week',\n"," ';',\n"," 'we',\n"," 'had',\n"," 'a',\n"," 'good',\n"," 'time',\n"," 'together']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"dxd9PFw1Oyvx"},"source":["In the above list ';' came as a seperate token compared to manual process"]},{"cell_type":"markdown","metadata":{"id":"wNAFzitqPROe"},"source":["# **RegexpTokenizer** - If we want to apply regular expressions and then want to extract the token"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mtZqAlmrNIlh","executionInfo":{"status":"ok","timestamp":1611042924184,"user_tz":-330,"elapsed":5508,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"b2e62675-cafa-4aec-a965-a7b33be33017"},"source":["from nltk.tokenize import RegexpTokenizer\r\n","tokenizer = RegexpTokenizer(r'\\w+') # setting the pattern to make tokens of only words and nothing else\r\n","tokens = tokenizer.tokenize(doc.lower()) \r\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'visited',\n"," 'my',\n"," 'grandparents',\n"," 'last',\n"," 'week',\n"," 'we',\n"," 'had',\n"," 'a',\n"," 'good',\n"," 'time',\n"," 'together']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"xPP3RT3pQfpJ"},"source":["doc2 = '@john This product is really cool!!!üòÄüòÉüòÑüòÅüòÜüòÖ #awesome'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQ3WuKTltgth","executionInfo":{"status":"ok","timestamp":1611042924187,"user_tz":-330,"elapsed":5496,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"4db83a4b-db57-48b6-e5da-1c4d068e3772"},"source":["tokens = word_tokenize(doc2)\r\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['@',\n"," 'john',\n"," 'This',\n"," 'product',\n"," 'is',\n"," 'really',\n"," 'cool',\n"," '!',\n"," '!',\n"," '!',\n"," 'üòÄüòÉüòÑüòÅüòÜüòÖ',\n"," '#',\n"," 'awesome']"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"x0_5wq_hvYc5"},"source":["* @john, #awesome should have come together but\r\n","* All the tokens except pair of smileys are coming in seperate lines"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GABop-eAvS8E","executionInfo":{"status":"ok","timestamp":1611042924190,"user_tz":-330,"elapsed":5488,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"41fa1097-a6cc-472e-9e28-45aaf67b6940"},"source":["from nltk.tokenize import TweetTokenizer\r\n","tweet_tokenizer = TweetTokenizer()\r\n","token1 = tweet_tokenizer.tokenize(doc2)\r\n","token1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['@john',\n"," 'This',\n"," 'product',\n"," 'is',\n"," 'really',\n"," 'cool',\n"," '!',\n"," '!',\n"," '!',\n"," 'üòÄ',\n"," 'üòÉ',\n"," 'üòÑ',\n"," 'üòÅ',\n"," 'üòÜ',\n"," 'üòÖ',\n"," '#awesome']"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"h_hfKPe-w_Ca"},"source":["* Now @john and #awesome are coming together as they should have and smileys are coming in seperate lines "]},{"cell_type":"markdown","metadata":{"id":"0S8OTqKLqrEI"},"source":["# Tokenization - CSV file read"]},{"cell_type":"markdown","metadata":{"id":"VY_6uSnTw-Oh"},"source":["[link text](https://)"]},{"cell_type":"code","metadata":{"id":"INWvaljvruSw"},"source":["!pip install -U -q PyDrive\r\n","from pydrive.auth import GoogleAuth\r\n","from pydrive.drive import GoogleDrive\r\n","from google.colab import auth\r\n","from oauth2client.client import GoogleCredentials"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbK_lcdQ0QhW"},"source":["auth.authenticate_user()\r\n","gauth = GoogleAuth()\r\n","gauth.credentials = GoogleCredentials.get_application_default()\r\n","drive = GoogleDrive(gauth)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HS-nl1e0VwC"},"source":["downloaded = drive.CreateFile({'id':'12CUjW29tTTxYAcPhxuKb_qSn0UTzc4BR'}) # replace the id with id of file you want to access\r\n","downloaded.GetContentFile('imdb_sentiment.csv') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"dhrU-olG3-Mv","executionInfo":{"status":"ok","timestamp":1611047092973,"user_tz":-330,"elapsed":1177,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"60650d57-45e7-45eb-cdaa-be5c15cbbdc3"},"source":["import pandas as pd\r\n","data = pd.read_csv('imdb_sentiment.csv')\r\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A very, very, very slow-moving, aimless movie ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Not sure who was more lost - the flat characte...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Attempting artiness with black &amp; white and cle...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Very little music or anything to speak of.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>The best scene in the movie was when Gerardo i...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  A very, very, very slow-moving, aimless movie ...          0\n","1  Not sure who was more lost - the flat characte...          0\n","2  Attempting artiness with black & white and cle...          0\n","3       Very little music or anything to speak of.            0\n","4  The best scene in the movie was when Gerardo i...          1"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1wbr9NO47tF","executionInfo":{"status":"ok","timestamp":1611054177105,"user_tz":-330,"elapsed":1590,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"7a4ddbd9-ecea-4bd6-80af-7961129854e8"},"source":["docs = data['review'].str.lower()\r\n","tokenizer = RegexpTokenizer('\\w+')\r\n","for x in docs.head():\r\n","  tokens = tokenizer.tokenize(x)\r\n","  print(x)\r\n","  print(tokens)\r\n","  print('-'*50)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["a very, very, very slow-moving, aimless movie about a distressed, drifting young man.  \n","['a', 'very', 'very', 'very', 'slow', 'moving', 'aimless', 'movie', 'about', 'a', 'distressed', 'drifting', 'young', 'man']\n","--------------------------------------------------\n","not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  \n","['not', 'sure', 'who', 'was', 'more', 'lost', 'the', 'flat', 'characters', 'or', 'the', 'audience', 'nearly', 'half', 'of', 'whom', 'walked', 'out']\n","--------------------------------------------------\n","attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.  \n","['attempting', 'artiness', 'with', 'black', 'white', 'and', 'clever', 'camera', 'angles', 'the', 'movie', 'disappointed', 'became', 'even', 'more', 'ridiculous', 'as', 'the', 'acting', 'was', 'poor', 'and', 'the', 'plot', 'and', 'lines', 'almost', 'non', 'existent']\n","--------------------------------------------------\n","very little music or anything to speak of.  \n","['very', 'little', 'music', 'or', 'anything', 'to', 'speak', 'of']\n","--------------------------------------------------\n","the best scene in the movie was when gerardo is trying to find a song that keeps running through his head.  \n","['the', 'best', 'scene', 'in', 'the', 'movie', 'was', 'when', 'gerardo', 'is', 'trying', 'to', 'find', 'a', 'song', 'that', 'keeps', 'running', 'through', 'his', 'head']\n","--------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AEUPA2zI78eX","executionInfo":{"status":"ok","timestamp":1611054434628,"user_tz":-330,"elapsed":1190,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"7dba80a9-fd1d-4ba2-b4fa-5142c3409fc9"},"source":["docs = data['review'].str.lower()\r\n","docs_cleaned = []\r\n","tokenizer = RegexpTokenizer('\\w+')\r\n","for x in docs.head():\r\n","  tokens = tokenizer.tokenize(x)\r\n","  docs_cleaned.append(tokens)\r\n","docs_cleaned"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['a',\n","  'very',\n","  'very',\n","  'very',\n","  'slow',\n","  'moving',\n","  'aimless',\n","  'movie',\n","  'about',\n","  'a',\n","  'distressed',\n","  'drifting',\n","  'young',\n","  'man'],\n"," ['not',\n","  'sure',\n","  'who',\n","  'was',\n","  'more',\n","  'lost',\n","  'the',\n","  'flat',\n","  'characters',\n","  'or',\n","  'the',\n","  'audience',\n","  'nearly',\n","  'half',\n","  'of',\n","  'whom',\n","  'walked',\n","  'out'],\n"," ['attempting',\n","  'artiness',\n","  'with',\n","  'black',\n","  'white',\n","  'and',\n","  'clever',\n","  'camera',\n","  'angles',\n","  'the',\n","  'movie',\n","  'disappointed',\n","  'became',\n","  'even',\n","  'more',\n","  'ridiculous',\n","  'as',\n","  'the',\n","  'acting',\n","  'was',\n","  'poor',\n","  'and',\n","  'the',\n","  'plot',\n","  'and',\n","  'lines',\n","  'almost',\n","  'non',\n","  'existent'],\n"," ['very', 'little', 'music', 'or', 'anything', 'to', 'speak', 'of'],\n"," ['the',\n","  'best',\n","  'scene',\n","  'in',\n","  'the',\n","  'movie',\n","  'was',\n","  'when',\n","  'gerardo',\n","  'is',\n","  'trying',\n","  'to',\n","  'find',\n","  'a',\n","  'song',\n","  'that',\n","  'keeps',\n","  'running',\n","  'through',\n","  'his',\n","  'head']]"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"kwNdnGzoVV3j"},"source":["* Here we have list of lists which contains list elements in rows for e.g.-> 1st row in docs became 1st list, 2nd row in docs became 2nd list "]},{"cell_type":"markdown","metadata":{"id":"czOOyIveTURm"},"source":["# Use spacy to get individual tokens"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwLYWOinUsXV","executionInfo":{"status":"ok","timestamp":1611055772113,"user_tz":-330,"elapsed":1666,"user":{"displayName":"Varun Rana","photoUrl":"","userId":"00188788562004174296"}},"outputId":"7a4199ad-bf77-4d99-a7f0-d769ebfbf00f"},"source":["nw_doc = 'I visited my grandparents last week; We had a good time together'\r\n","\r\n","import spacy\r\n","nlp = spacy.load('en_core_web_sm') # Necessary corpus required to do text cleaning and processing operations \r\n","\r\n","spacy_doc = nlp(nw_doc.lower())\r\n","\r\n","for x in spacy_doc:\r\n","  print(x)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["i\n","visited\n","my\n","grandparents\n","last\n","week\n",";\n","we\n","had\n","a\n","good\n","time\n","together\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"khYhIa-EaPnO"},"source":["* Here we got individual tokens automatically from a single document "]},{"cell_type":"code","metadata":{"id":"PUeNWEPBafYD"},"source":[""],"execution_count":null,"outputs":[]}]}