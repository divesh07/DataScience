{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e96054-5348-4acc-9520-65baaecc0e76",
   "metadata": {},
   "source": [
    "# **Session - 5** :Spark Higher API\n",
    "## **Agenda**\n",
    "- Why DF(Higher level API) over RDD.\n",
    "- Intro to DF and Sparksql\n",
    "- Creating Dataframe\n",
    "- Basic Operations\n",
    "- Transformations\n",
    "- Writing Dataframes\n",
    "- Working with Spark sql,managed view/table, metadata\n",
    "- Databricks in cloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41007ea5-25d9-48fb-bff7-e728167fb9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 06:08:20,765 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2024-09-08 06:08:22,220 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Sparksession boilerplate code\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "try:\n",
    "    username = getpass.getuser()\n",
    "\n",
    "    # Create a Spark session\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"MySparkApp\") \\\n",
    "        .config('spark.ui.port', '0') \\\n",
    "        .config(\"spark.sql.warehouse.dir\", f\"/user/tplbigdattrain/datasets/dsml-8/Spark-session/Spark-DF-API/warehouse\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .master('yarn') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # Log the Spark configuration to help with debugging\n",
    "    print(\"Spark Session created successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while creating the Spark session:\")\n",
    "    print(str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f278be-c192-4d4b-9b0a-c47ae6357ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-16-182.ap-south-1.compute.internal:42277\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>MySparkApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb5f918b3a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c49d32a-bdfb-4f42-94de-d077572325d0",
   "metadata": {},
   "source": [
    "## Why DF(Higher level API) over RDD?\n",
    "1. Schema awareness\n",
    "2. Optimized\n",
    "3. Easy to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f5d2d2-4ba5-4893-8e37-f0e9945b2fb5",
   "metadata": {},
   "source": [
    "\n",
    "## **DataFrames**\n",
    "\n",
    "### Introduction\n",
    "DataFrames in Spark are distributed collections of data organized into named columns, similar to tables in relational databases. They provide a higher-level API for manipulating structured data and are integrated with Spark’s Catalyst optimizer and Tungsten execution engine, offering significant performance benefits.\n",
    "\n",
    "#### Key Features\n",
    "\n",
    "1. **Schema**: DataFrames have a schema, which defines the names and types of the columns.\n",
    "2. **API**: They offer a rich API for performing operations such as filtering, grouping, aggregating, and joining.\n",
    "3. **Optimization**: DataFrames benefit from Spark’s Catalyst optimizer for query optimization and Tungsten execution engine for efficient computation.\n",
    "4. **Interoperability**: They can be created from various data sources like JSON, CSV, Parquet, Avro, Hiv\n",
    "### Note: Dataframes -> Temporary Nature\n",
    "- DataFrames are temporary and exist only for the duration of the Spark session. Once the application is closed, the DataFrame will no longer be available.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Spark SQL**\n",
    "\n",
    "### Introduction\n",
    "Spark SQL allows users to query structured data using SQL syntax. It is tightly integrated with the Spark DataFrame API, enabling users to leverage SQL queries for data processing.\n",
    "\n",
    "### Features\n",
    "- **SQL Queries**: Perform operations using familiar SQL syntax.\n",
    "- **Temporary Views**: Create temporary views from DataFrames to run SQL queries.\n",
    "- **Optimization**: Benefit from Spark’s query optimization mechanisms.\n",
    "\n",
    "### Example\n",
    "1. **Creating a Temporary View**: Create a temporary view from a DataFrame.\n",
    "\n",
    "   ```ddf.createOrReplaceTempView(\"temp_view_name\")```\n",
    "\n",
    "\n",
    "2. **Running SQL Queries**: Execute SQL queries on the temporary view.\n",
    "\n",
    "   ```spark.sql(\"SELECT * FROM temp_view_name WHERE age > 21\").show()```\n",
    "\n",
    "### Note: SQL tables -> Persistent Tables\n",
    "- Spark tables are persistent and accessible across different sessions. They are stored in a metastore, making them permanent and reusable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56762efe-1c61-441a-a4f0-f1aa7437605f",
   "metadata": {},
   "source": [
    "## Various ways to create Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d5b9ce-07ca-4979-97f4-e3e214f7b4a4",
   "metadata": {},
   "source": [
    "## 1. DF from txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5690bf75-2e85-4500-8ea0-cbcd6f37a36f",
   "metadata": {},
   "source": [
    "dsml-8/students_data.txt - not usable\n",
    "- Compltiable file formates\n",
    "1. csv\n",
    "2. parquet\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba37319-bf86-4c82-8ce2-a68e318ee739",
   "metadata": {},
   "source": [
    "### RDD to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3353215a-b252-4625-9f13-964e7ec7fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['101 A Rohit Gurgaon 65 77 43 66 87',\n",
       " '102 B Akansha Delhi 55 46 24 66 77',\n",
       " '103 A Himanshu Faridabad 75 38 84 38 58',\n",
       " '104 A Ekta Delhi 85 84 39 58 85',\n",
       " '105 B Deepanshu Gurgaon 34 55 56 23 66',\n",
       " '106 B Ayush Delhi 66 62 98 74 87',\n",
       " '107 B Aditi Delhi 76 83 75 38 58',\n",
       " '108 A Sahil Faridabad 55 32 43 56 66',\n",
       " '109 A Krati Delhi 34 53 25 67 75']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "path='dsml-8/students_data.txt'\n",
    "students_data_rdd = sc.textFile(path)\n",
    "students_data_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a2647ce-b12c-4ab8-a096-1ef875da0ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['101', 'A', 'Rohit', 'Gurgaon', '65', '77', '43', '66', '87'],\n",
       " ['102', 'B', 'Akansha', 'Delhi', '55', '46', '24', '66', '77'],\n",
       " ['103', 'A', 'Himanshu', 'Faridabad', '75', '38', '84', '38', '58'],\n",
       " ['104', 'A', 'Ekta', 'Delhi', '85', '84', '39', '58', '85'],\n",
       " ['105', 'B', 'Deepanshu', 'Gurgaon', '34', '55', '56', '23', '66'],\n",
       " ['106', 'B', 'Ayush', 'Delhi', '66', '62', '98', '74', '87'],\n",
       " ['107', 'B', 'Aditi', 'Delhi', '76', '83', '75', '38', '58'],\n",
       " ['108', 'A', 'Sahil', 'Faridabad', '55', '32', '43', '56', '66'],\n",
       " ['109', 'A', 'Krati', 'Delhi', '34', '53', '25', '67', '75']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_rdd_map = students_data_rdd.map(lambda x:x.split(' '))\n",
    "std_rdd_map.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df09b90-4a0b-4369-9745-f0b8a1b26680",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df = std_rdd_map.toDF(['rollno','section','name','city','s1','s2','s3','s4','s5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a842e5f9-785e-4352-a5e5-d626f3f385cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+---------+---------+---+---+---+---+---+\n",
      "|rollno|section|     name|     city| s1| s2| s3| s4| s5|\n",
      "+------+-------+---------+---------+---+---+---+---+---+\n",
      "|   101|      A|    Rohit|  Gurgaon| 65| 77| 43| 66| 87|\n",
      "|   102|      B|  Akansha|    Delhi| 55| 46| 24| 66| 77|\n",
      "|   103|      A| Himanshu|Faridabad| 75| 38| 84| 38| 58|\n",
      "|   104|      A|     Ekta|    Delhi| 85| 84| 39| 58| 85|\n",
      "|   105|      B|Deepanshu|  Gurgaon| 34| 55| 56| 23| 66|\n",
      "|   106|      B|    Ayush|    Delhi| 66| 62| 98| 74| 87|\n",
      "|   107|      B|    Aditi|    Delhi| 76| 83| 75| 38| 58|\n",
      "|   108|      A|    Sahil|Faridabad| 55| 32| 43| 56| 66|\n",
      "|   109|      A|    Krati|    Delhi| 34| 53| 25| 67| 75|\n",
      "+------+-------+---------+---------+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c697b53-7d50-4bb5-bb55-4a05a8ae6121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- rollno: string (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- s1: string (nullable = true)\n",
      " |-- s2: string (nullable = true)\n",
      " |-- s3: string (nullable = true)\n",
      " |-- s4: string (nullable = true)\n",
      " |-- s5: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc25d3-d6c5-4354-9cb8-3bdb0d4ca0b2",
   "metadata": {},
   "source": [
    "## 2. DF from collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b82eda21-fa9f-460d-88ab-ca994439c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection\n",
    "sample_data = [\n",
    "    (101, \"A\", \"Rohit\",    \"Gurugram\"),\n",
    "    (102, \"B\", \"Akansha\",  \"Delhi\"),\n",
    "    (103, \"A\", \"Himanshu\", \"Faridabad\"),\n",
    "    (104, \"A\", \"Ekta\",     \"Delhi\"),\n",
    "    (105, \"B\", \"Ayush\",    \"Delhi\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bc53d9d-8ded-41fe-a7bf-bfbf42655aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+---------+\n",
      "|rollno|section|    name|     city|\n",
      "+------+-------+--------+---------+\n",
      "|   101|      A|   Rohit| Gurugram|\n",
      "|   102|      B| Akansha|    Delhi|\n",
      "|   103|      A|Himanshu|Faridabad|\n",
      "|   104|      A|    Ekta|    Delhi|\n",
      "|   105|      B|   Ayush|    Delhi|\n",
      "+------+-------+--------+---------+\n",
      "\n",
      "root\n",
      " |-- rollno: long (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_from_coll = spark.createDataFrame(data=sample_data,schema=['rollno','section','name','city'])\n",
    "df_from_coll.show()\n",
    "df_from_coll.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac914be-d89a-4fd1-bd5a-91b54fa34dd1",
   "metadata": {},
   "source": [
    "# Spark DataFrame from any file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c53500c-7549-4e66-871a-854d25a03dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+---------+---+---+---+---+---+\n",
      "|101|  A|    Rohit|  Gurgaon| 65| 77| 43| 66| 87|\n",
      "+---+---+---------+---------+---+---+---+---+---+\n",
      "|102|  B|  Akansha|    Delhi| 55| 46| 24| 66| 77|\n",
      "|103|  A| Himanshu|Faridabad| 75| 38| 84| 38| 58|\n",
      "|104|  A|     Ekta|    Delhi| 85| 84| 39| 58| 85|\n",
      "|105|  B|Deepanshu|  Gurgaon| 34| 55| 56| 23| 66|\n",
      "|106|  B|    Ayush|    Delhi| 66| 62| 98| 74| 87|\n",
      "|107|  B|    Aditi|    Delhi| 76| 83| 75| 38| 58|\n",
      "|108|  A|    Sahil|Faridabad| 55| 32| 43| 56| 66|\n",
      "|109|  A|    Krati|    Delhi| 34| 53| 25| 67| 75|\n",
      "+---+---+---------+---------+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'dsml-8/module_8_students_data.csv'\n",
    "df_csv1 = spark.read.csv(path,header=True)\n",
    "df_csv1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb1a996c-91f2-42bb-9925-dc34f2a929fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---------+---------+---+---+---+---+---+\n",
      "|101|  A|    Rohit|  Gurgaon| 65| 77| 43| 66| 87|\n",
      "+---+---+---------+---------+---+---+---+---+---+\n",
      "|102|  B|  Akansha|    Delhi| 55| 46| 24| 66| 77|\n",
      "|103|  A| Himanshu|Faridabad| 75| 38| 84| 38| 58|\n",
      "|104|  A|     Ekta|    Delhi| 85| 84| 39| 58| 85|\n",
      "|105|  B|Deepanshu|  Gurgaon| 34| 55| 56| 23| 66|\n",
      "|106|  B|    Ayush|    Delhi| 66| 62| 98| 74| 87|\n",
      "|107|  B|    Aditi|    Delhi| 76| 83| 75| 38| 58|\n",
      "|108|  A|    Sahil|Faridabad| 55| 32| 43| 56| 66|\n",
      "|109|  A|    Krati|    Delhi| 34| 53| 25| 67| 75|\n",
      "+---+---+---------+---------+---+---+---+---+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_csv2 = spark.read.format(\"csv\").option('header',True).option('inferSchema',True).load(path)\n",
    "df_csv2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679b990-6b48-4e49-9580-fc5263842398",
   "metadata": {},
   "source": [
    "## Schema Enforcement\n",
    "### 2 Ways:\n",
    "1. Explicit Schema enforcement.(structField, structType. datatype)\n",
    "2. Implicit schema enforcement.(inferSchema) with Renaming the columns\n",
    "\n",
    "#### Various datatype:\n",
    "1. IntegerType\n",
    "2. StringType\n",
    "3. Datetime\n",
    "4. longtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ede6ac9d-6c03-40d7-98cd-3e94a03e1bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8752a00c-da68-4ebf-9c19-2a505e74c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_schema = tp.StructType([\n",
    "    tp.StructField(name= \"roll_no\", dataType= tp.IntegerType()),\n",
    "    tp.StructField(name= \"section\", dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"name\",    dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"city\",    dataType= tp.StringType()),\n",
    "    tp.StructField(name= \"subject1\",dataType= tp.IntegerType()),\n",
    "    tp.StructField(name= \"subject2\",dataType= tp.IntegerType()),\n",
    "    tp.StructField(name= \"subject3\",dataType= tp.IntegerType()),\n",
    "    tp.StructField(name= \"subject4\",dataType= tp.IntegerType()),\n",
    "    tp.StructField(name= \"subject5\",dataType= tp.IntegerType()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0947677-5de1-4f05-aaaa-a9101a00adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
      "|roll_no|section|     name|     city|subject1|subject2|subject3|subject4|subject5|\n",
      "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
      "|    102|      B|  Akansha|    Delhi|      55|      46|      24|      66|      77|\n",
      "|    103|      A| Himanshu|Faridabad|      75|      38|      84|      38|      58|\n",
      "|    104|      A|     Ekta|    Delhi|      85|      84|      39|      58|      85|\n",
      "|    105|      B|Deepanshu|  Gurgaon|      34|      55|      56|      23|      66|\n",
      "|    106|      B|    Ayush|    Delhi|      66|      62|      98|      74|      87|\n",
      "|    107|      B|    Aditi|    Delhi|      76|      83|      75|      38|      58|\n",
      "|    108|      A|    Sahil|Faridabad|      55|      32|      43|      56|      66|\n",
      "|    109|      A|    Krati|    Delhi|      34|      53|      25|      67|      75|\n",
      "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
      "\n",
      "root\n",
      " |-- roll_no: integer (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- subject1: integer (nullable = true)\n",
      " |-- subject2: integer (nullable = true)\n",
      " |-- subject3: integer (nullable = true)\n",
      " |-- subject4: integer (nullable = true)\n",
      " |-- subject5: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv2 = spark.read.csv(path,header=True,schema=my_schema)\n",
    "df_csv2.show()\n",
    "df_csv2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac02d541-b76b-466d-8cb9-922dc6ef58ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
      "|roll_no|section|     name|     city|subject1|subject2|subject3|subject4|subject5|\n",
      "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
      "|    102|      B|  Akansha|    Delhi|      55|      46|      24|      66|      77|\n",
      "|    103|      A| Himanshu|Faridabad|      75|      38|      84|      38|      58|\n",
      "|    104|      A|     Ekta|    Delhi|      85|      84|      39|      58|      85|\n",
      "|    105|      B|Deepanshu|  Gurgaon|      34|      55|      56|      23|      66|\n",
      "|    106|      B|    Ayush|    Delhi|      66|      62|      98|      74|      87|\n",
      "|    107|      B|    Aditi|    Delhi|      76|      83|      75|      38|      58|\n",
      "|    108|      A|    Sahil|Faridabad|      55|      32|      43|      56|      66|\n",
      "|    109|      A|    Krati|    Delhi|      34|      53|      25|      67|      75|\n",
      "+-------+-------+---------+---------+--------+--------+--------+--------+--------+\n",
      "\n",
      "root\n",
      " |-- roll_no: integer (nullable = true)\n",
      " |-- section: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- subject1: integer (nullable = true)\n",
      " |-- subject2: integer (nullable = true)\n",
      " |-- subject3: integer (nullable = true)\n",
      " |-- subject4: integer (nullable = true)\n",
      " |-- subject5: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv21 = spark.read.format(\"csv\").option('header',True).schema(my_schema).load(path)\n",
    "df_csv21.show()\n",
    "df_csv21.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55545f-b5eb-45c0-ae88-215197869e2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<center><h1> DataFrames Operations </h1></center>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "* 1. **Print Schema**\n",
    "* 2. **Column Names**\n",
    "* 3. **Check the Dimensions of the Data**\n",
    "* 4. **Select Columns**\n",
    "* 5. **Drop**\n",
    "* 6. **Retrieve specific records**\n",
    "* 7. **Add new columns**\n",
    "* 8. **Sorting**\n",
    "* 9. **GroupBy & Aggregation Functions**\n",
    "\n",
    "---\n",
    "\n",
    "We are going to use the Healthcare Analytics(**dsml-8/hospital_train.csv**) Data which has 18 different columns -\n",
    "\n",
    " - case_id\n",
    " - hospital_code\n",
    " - hospital_type_code\n",
    " - city_code_hospital\n",
    " - hospital_region_code\n",
    " - extra_room_available\n",
    " - department\n",
    " - ward_type\n",
    " - ward_facility_code\n",
    " - bed_grade\n",
    " - patient_id\n",
    " - city_code_patient\n",
    " - admission_type\n",
    " - severity_of_illness\n",
    " - visitors_with_patient\n",
    " - age\n",
    " - admission_deposit\n",
    " - stay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd907a69-866a-448b-8b46-f40277e64088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "|case_id|Hospital_code|Hospital_type_code|City_Code_Hospital|Hospital_region_code|Available Extra Rooms in Hospital|  Department|Ward_Type|Ward_Facility_Code|Bed Grade|patientid|City_Code_Patient|Type of Admission|Severity of Illness|Visitors with Patient|  Age|Admission_Deposit| Stay|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "|      1|            8|                 c|                 3|                   Z|                                3|radiotherapy|        R|                 F|      2.0|    31397|              7.0|        Emergency|            Extreme|                    2|51-60|           4911.0| 0-10|\n",
      "|      2|            2|                 c|                 5|                   Z|                                2|radiotherapy|        S|                 F|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           5954.0|41-50|\n",
      "|      3|           10|                 e|                 1|                   X|                                2|  anesthesia|        S|                 E|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           4745.0|31-40|\n",
      "|      4|           26|                 b|                 2|                   Y|                                2|radiotherapy|        R|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           7272.0|41-50|\n",
      "|      5|           26|                 b|                 2|                   Y|                                2|radiotherapy|        S|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           5558.0|41-50|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- case_id: integer (nullable = true)\n",
      " |-- Hospital_code: integer (nullable = true)\n",
      " |-- Hospital_type_code: string (nullable = true)\n",
      " |-- City_Code_Hospital: integer (nullable = true)\n",
      " |-- Hospital_region_code: string (nullable = true)\n",
      " |-- Available Extra Rooms in Hospital: integer (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Ward_Type: string (nullable = true)\n",
      " |-- Ward_Facility_Code: string (nullable = true)\n",
      " |-- Bed Grade: double (nullable = true)\n",
      " |-- patientid: integer (nullable = true)\n",
      " |-- City_Code_Patient: double (nullable = true)\n",
      " |-- Type of Admission: string (nullable = true)\n",
      " |-- Severity of Illness: string (nullable = true)\n",
      " |-- Visitors with Patient: integer (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Admission_Deposit: double (nullable = true)\n",
      " |-- Stay: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.format('csv').option('header',True).option('inferSchema',True).load('dsml-8/hospital_train.csv')\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "49166560-7294-48cc-95ce-889dc6202192",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'minParition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_878880/2234314691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminParition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \"\"\"\n\u001b[1;32m   1642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1643\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   1644\u001b[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[1;32m   1645\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'minParition'"
     ]
    }
   ],
   "source": [
    "df.minParition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e7e0197-301c-4c0d-aa7e-0a99cb322d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['case_id',\n",
       " 'Hospital_code',\n",
       " 'Hospital_type_code',\n",
       " 'City_Code_Hospital',\n",
       " 'Hospital_region_code',\n",
       " 'Available Extra Rooms in Hospital',\n",
       " 'Department',\n",
       " 'Ward_Type',\n",
       " 'Ward_Facility_Code',\n",
       " 'Bed Grade',\n",
       " 'patientid',\n",
       " 'City_Code_Patient',\n",
       " 'Type of Admission',\n",
       " 'Severity of Illness',\n",
       " 'Visitors with Patient',\n",
       " 'Age',\n",
       " 'Admission_Deposit',\n",
       " 'Stay']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad3664-597a-48da-b9d5-5c95420ac440",
   "metadata": {},
   "source": [
    "#### Check the Dimensions of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7ae9a58-9a72-41f9-adc4-0c62674cb4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318438, 18)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.count(),len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc686005-0271-42c9-86a8-ad91102e38c1",
   "metadata": {},
   "source": [
    "#### Select Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6da8fae-d919-453a-ad5c-9969c932626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+-----------------+-----+\n",
      "|case_id|patientid|  Age|Admission_Deposit| Stay|\n",
      "+-------+---------+-----+-----------------+-----+\n",
      "|      1|    31397|51-60|           4911.0| 0-10|\n",
      "|      2|    31397|51-60|           5954.0|41-50|\n",
      "|      3|    31397|51-60|           4745.0|31-40|\n",
      "|      4|    31397|51-60|           7272.0|41-50|\n",
      "|      5|    31397|51-60|           5558.0|41-50|\n",
      "|      6|    31397|51-60|           4449.0|11-20|\n",
      "|      7|    31397|51-60|           6167.0| 0-10|\n",
      "|      8|    31397|51-60|           5571.0|41-50|\n",
      "|      9|    31397|51-60|           7223.0|51-60|\n",
      "|     10|    31397|51-60|           6056.0|31-40|\n",
      "|     11|    31397|51-60|           5797.0|21-30|\n",
      "|     12|    31397|51-60|           5993.0|11-20|\n",
      "|     13|    31397|51-60|           5141.0| 0-10|\n",
      "|     14|    31397|51-60|           8477.0|21-30|\n",
      "|     15|    63418|71-80|           2685.0| 0-10|\n",
      "|     16|    63418|71-80|           9398.0| 0-10|\n",
      "|     17|    63418|71-80|           2933.0| 0-10|\n",
      "|     18|    63418|71-80|           5342.0|11-20|\n",
      "|     19|    63418|71-80|           7442.0|21-30|\n",
      "|     20|    63418|71-80|           5155.0|31-40|\n",
      "+-------+---------+-----+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data = df.select('case_id','patientid','Age','Admission_Deposit','Stay')\n",
    "sample_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192efd8b-bb0a-4365-b2a5-dab59279a870",
   "metadata": {},
   "source": [
    "### Creating Spark SQl table from Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f9cf4da-b30b-4941-82a5-6f42c9a484b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.createOrReplaceTempView('xyz')# TempView(view or table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e210fba8-ba46-4d1a-8378-328899ce1c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+-----------------+-----+\n",
      "|case_id|patientid|  Age|Admission_Deposit| Stay|\n",
      "+-------+---------+-----+-----------------+-----+\n",
      "|      1|    31397|51-60|           4911.0| 0-10|\n",
      "|      2|    31397|51-60|           5954.0|41-50|\n",
      "|      3|    31397|51-60|           4745.0|31-40|\n",
      "|      4|    31397|51-60|           7272.0|41-50|\n",
      "|      5|    31397|51-60|           5558.0|41-50|\n",
      "+-------+---------+-----+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from xyz where Admission_Deposit > 3000 limit 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0ccab99-c927-447b-aff6-3b437446a063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 04:56:26,925 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2024-09-08 04:56:26,925 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2024-09-08 04:56:32,181 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "2024-09-08 04:56:32,181 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore tplbigdattrain@172.31.16.182\n",
      "2024-09-08 04:56:32,199 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+-------+\n",
      "|         col_name|data_type|comment|\n",
      "+-----------------+---------+-------+\n",
      "|          case_id|      int|   null|\n",
      "|        patientid|      int|   null|\n",
      "|              Age|   string|   null|\n",
      "|Admission_Deposit|   double|   null|\n",
      "|             Stay|   string|   null|\n",
      "+-----------------+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 04:56:32,877 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    }
   ],
   "source": [
    "spark.sql('describe table xyz').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e30238a-dae4-41ce-b24b-eae9f201234c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+-------+\n",
      "|         col_name|data_type|comment|\n",
      "+-----------------+---------+-------+\n",
      "|          case_id|      int|   null|\n",
      "|        patientid|      int|   null|\n",
      "|              Age|   string|   null|\n",
      "|Admission_Deposit|   double|   null|\n",
      "|             Stay|   string|   null|\n",
      "+-----------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('describe formatted xyz').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d5bcc-e6e4-482d-bd3c-2fa2e48af21a",
   "metadata": {},
   "source": [
    "## Drop column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fefdb99-0b79-485c-a0bd-46a5c283a4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "|case_id|Hospital_code|Hospital_type_code|City_Code_Hospital|Hospital_region_code|Available Extra Rooms in Hospital|  Department|Ward_Type|Ward_Facility_Code|Bed Grade|patientid|City_Code_Patient|Type of Admission|Severity of Illness|Visitors with Patient|  Age|Admission_Deposit| Stay|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "|      1|            8|                 c|                 3|                   Z|                                3|radiotherapy|        R|                 F|      2.0|    31397|              7.0|        Emergency|            Extreme|                    2|51-60|           4911.0| 0-10|\n",
      "|      2|            2|                 c|                 5|                   Z|                                2|radiotherapy|        S|                 F|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           5954.0|41-50|\n",
      "|      3|           10|                 e|                 1|                   X|                                2|  anesthesia|        S|                 E|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           4745.0|31-40|\n",
      "|      4|           26|                 b|                 2|                   Y|                                2|radiotherapy|        R|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           7272.0|41-50|\n",
      "|      5|           26|                 b|                 2|                   Y|                                2|radiotherapy|        S|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           5558.0|41-50|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac9152e0-ae56-44a2-b2c0-a930ac369cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----------------+-----+\n",
      "|case_id|Hospital_code|Hospital_type_code|City_Code_Hospital|Hospital_region_code|Available Extra Rooms in Hospital|  Department|Ward_Type|Ward_Facility_Code|Bed Grade|patientid|City_Code_Patient|Type of Admission|Severity of Illness|Visitors with Patient|Admission_Deposit| Stay|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----------------+-----+\n",
      "|      1|            8|                 c|                 3|                   Z|                                3|radiotherapy|        R|                 F|      2.0|    31397|              7.0|        Emergency|            Extreme|                    2|           4911.0| 0-10|\n",
      "|      2|            2|                 c|                 5|                   Z|                                2|radiotherapy|        S|                 F|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|           5954.0|41-50|\n",
      "|      3|           10|                 e|                 1|                   X|                                2|  anesthesia|        S|                 E|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|           4745.0|31-40|\n",
      "|      4|           26|                 b|                 2|                   Y|                                2|radiotherapy|        R|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|           7272.0|41-50|\n",
      "|      5|           26|                 b|                 2|                   Y|                                2|radiotherapy|        S|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|           5558.0|41-50|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_without_age = df.drop('age')\n",
    "df_without_age.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a6beb0d-e66b-43c0-90be-a127f3245072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----------------+-----+\n",
      "|case_id|Hospital_code|Hospital_type_code|City_Code_Hospital|Hospital_region_code|Available Extra Rooms in Hospital|Ward_Facility_Code|Bed Grade|patientid|City_Code_Patient|Type of Admission|Severity of Illness|Visitors with Patient|Admission_Deposit| Stay|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----------------+-----+\n",
      "|      1|            8|                 c|                 3|                   Z|                                3|                 F|      2.0|    31397|              7.0|        Emergency|            Extreme|                    2|           4911.0| 0-10|\n",
      "|      2|            2|                 c|                 5|                   Z|                                2|                 F|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|           5954.0|41-50|\n",
      "|      3|           10|                 e|                 1|                   X|                                2|                 E|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|           4745.0|31-40|\n",
      "|      4|           26|                 b|                 2|                   Y|                                2|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|           7272.0|41-50|\n",
      "|      5|           26|                 b|                 2|                   Y|                                2|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|           5558.0|41-50|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_drop_multi = df.drop(*['age','department','Ward_Type'])\n",
    "df_drop_multi.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9540b1-8f9e-4c01-9da4-ae56330751ec",
   "metadata": {},
   "source": [
    "### Single Filtering:where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a56c2f99-b8e0-4c37-9a9f-a0288ad1dfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "|case_id|Hospital_code|Hospital_type_code|City_Code_Hospital|Hospital_region_code|Available Extra Rooms in Hospital|  Department|Ward_Type|Ward_Facility_Code|Bed Grade|patientid|City_Code_Patient|Type of Admission|Severity of Illness|Visitors with Patient|  Age|Admission_Deposit| Stay|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "|      1|            8|                 c|                 3|                   Z|                                3|radiotherapy|        R|                 F|      2.0|    31397|              7.0|        Emergency|            Extreme|                    2|51-60|           4911.0| 0-10|\n",
      "|     56|            8|                 c|                 3|                   Z|                                2|radiotherapy|        R|                 F|      4.0|    33340|              2.0|        Emergency|           Moderate|                    2|31-40|           5130.0|21-30|\n",
      "|    179|            8|                 c|                 3|                   Z|                                7|  gynecology|        Q|                 F|      4.0|   117334|              4.0|           Trauma|           Moderate|                    4|31-40|           4244.0|21-30|\n",
      "|    510|            8|                 c|                 3|                   Z|                                2|  gynecology|        R|                 F|      2.0|    52406|              9.0|           Trauma|           Moderate|                    2|71-80|           4782.0|11-20|\n",
      "|    514|            8|                 c|                 3|                   Z|                                2|  gynecology|        Q|                 F|      4.0|    52406|              9.0|           Urgent|           Moderate|                    2|71-80|           4912.0|21-30|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.Hospital_code == 8).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4bcd5-8981-42ec-9fda-a0528533d0ae",
   "metadata": {},
   "source": [
    "### Multiple Filtering:where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "242033f2-86fa-44aa-aea0-f34a169e2c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+----------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "|case_id|Hospital_code|Hospital_type_code|City_Code_Hospital|Hospital_region_code|Available Extra Rooms in Hospital|Department|Ward_Type|Ward_Facility_Code|Bed Grade|patientid|City_Code_Patient|Type of Admission|Severity of Illness|Visitors with Patient|  Age|Admission_Deposit| Stay|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+----------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "|    179|            8|                 c|                 3|                   Z|                                7|gynecology|        Q|                 F|      4.0|   117334|              4.0|           Trauma|           Moderate|                    4|31-40|           4244.0|21-30|\n",
      "|    510|            8|                 c|                 3|                   Z|                                2|gynecology|        R|                 F|      2.0|    52406|              9.0|           Trauma|           Moderate|                    2|71-80|           4782.0|11-20|\n",
      "|    514|            8|                 c|                 3|                   Z|                                2|gynecology|        Q|                 F|      4.0|    52406|              9.0|           Urgent|           Moderate|                    2|71-80|           4912.0|21-30|\n",
      "|    535|            8|                 c|                 3|                   Z|                                4|gynecology|        R|                 F|      3.0|    90761|              4.0|           Trauma|              Minor|                    2|41-50|           4757.0|21-30|\n",
      "|    616|            8|                 c|                 3|                   Z|                                4|gynecology|        R|                 F|      2.0|   100741|             14.0|           Trauma|           Moderate|                    2|31-40|           4739.0|21-30|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+----------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where((df.Hospital_code == 8) & (df.Department=='gynecology')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bbbc9b-462f-4fd1-9488-e4a5170657ef",
   "metadata": {},
   "source": [
    "### new column :  .withColumn()\n",
    "- new column or transform exsisting one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c04f3c-b58d-4ccc-8a96-33b32b3f8aa0",
   "metadata": {},
   "source": [
    "#### New Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12990742-34d1-4f5c-bf0a-4ca452f4c590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+--------------------+\n",
      "|case_id|Hospital_code|Hospital_type_code|City_Code_Hospital|Hospital_region_code|Available Extra Rooms in Hospital|  Department|Ward_Type|Ward_Facility_Code|Bed Grade|patientid|City_Code_Patient|Type of Admission|Severity of Illness|Visitors with Patient|  Age|Admission_Deposit| Stay|deposite_per_vistior|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+--------------------+\n",
      "|      1|            8|                 c|                 3|                   Z|                                3|radiotherapy|        R|                 F|      2.0|    31397|              7.0|        Emergency|            Extreme|                    2|51-60|           4911.0| 0-10|              2455.5|\n",
      "|      2|            2|                 c|                 5|                   Z|                                2|radiotherapy|        S|                 F|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           5954.0|41-50|              2977.0|\n",
      "|      3|           10|                 e|                 1|                   X|                                2|  anesthesia|        S|                 E|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           4745.0|31-40|              2372.5|\n",
      "|      4|           26|                 b|                 2|                   Y|                                2|radiotherapy|        R|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           7272.0|41-50|              3636.0|\n",
      "|      5|           26|                 b|                 2|                   Y|                                2|radiotherapy|        S|                 D|      2.0|    31397|              7.0|           Trauma|            Extreme|                    2|51-60|           5558.0|41-50|              2779.0|\n",
      "+-------+-------------+------------------+------------------+--------------------+---------------------------------+------------+---------+------------------+---------+---------+-----------------+-----------------+-------------------+---------------------+-----+-----------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_new = df.withColumn('deposite_per_vistior',col('Admission_Deposit')/col('Visitors with Patient'))\n",
    "df_new.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44439c87-4ee5-42d3-910b-4506d2198381",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e3a8e76-51c7-4a18-b411-16de09427f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|Hospital_code|   Age|\n",
      "+-------------+------+\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1|91-100|\n",
      "|            1| 81-90|\n",
      "|            1| 81-90|\n",
      "|            1| 81-90|\n",
      "|            1| 81-90|\n",
      "|            1| 81-90|\n",
      "|            1| 81-90|\n",
      "|            1| 81-90|\n",
      "|            1| 81-90|\n",
      "|            1| 81-90|\n",
      "+-------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_df = df.sort(col('Hospital_code').asc(),col('Age').desc())\n",
    "sorted_df.select('Hospital_code','Age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af62252d-68aa-4314-a67f-d5ffe3a34162",
   "metadata": {},
   "source": [
    "### Groupby and agg function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aed35fd-fc9b-46fc-9b84-024101b40053",
   "metadata": {},
   "source": [
    "#### .withColumn- manipulating with values inside tbale\n",
    "#### .withRenamedColumn - change column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "549c8973-d3d6-4c09-8d6a-4ceba6352ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------------+\n",
      "|Hospital_code|Avg_admission_deposit|\n",
      "+-------------+---------------------+\n",
      "|            1|    5080.219089350352|\n",
      "|            2|   5000.1293610348885|\n",
      "|            3|    4829.677206295672|\n",
      "|            4|    5496.309677419355|\n",
      "|            5|    4935.027941455997|\n",
      "|            6|    4584.582815177479|\n",
      "|            7|    5608.380551301684|\n",
      "|            8|    4933.259623259623|\n",
      "|            9|    4853.857167680278|\n",
      "|           10|    4555.867090620031|\n",
      "|           11|    4926.203716528163|\n",
      "|           12|    4779.087191289723|\n",
      "|           13|    5118.668449197861|\n",
      "|           14|     4820.88758079409|\n",
      "|           15|   5333.8652911310355|\n",
      "|           16|     5229.39171887769|\n",
      "|           17|    4933.987820396292|\n",
      "|           18|    4548.159504132232|\n",
      "|           19|    4492.418728498044|\n",
      "|           20|    5190.156583629893|\n",
      "+-------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_df = df.groupby('Hospital_code') \\\n",
    "    .agg({'Admission_Deposit':'avg'}) \\\n",
    "    .withColumnRenamed('avg(Admission_Deposit)','Avg_admission_deposit') \\\n",
    "    .sort(col('Hospital_code').asc(),col('Avg_admission_deposit').desc())\n",
    "group_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0221801a-64cb-4ce5-9dfe-b040ffbd77a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "group_df.write.csv('dsml-8/output/heath_group.csv',header=True,mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ae09e06-e808-4fb3-8e65-cf7b4ba59e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "group_df.write.parquet('dsml-8/o',mode='overwrite')utput/parquet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "671c2c95-131f-4bb4-a0a5-4fe3128b24cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------------+\n",
      "|Hospital_code|Avg_admission_deposit|\n",
      "+-------------+---------------------+\n",
      "|           15|   5333.8652911310355|\n",
      "|           22|   4942.3895253682485|\n",
      "|            2|   5000.1293610348885|\n",
      "|           10|    4555.867090620031|\n",
      "|           11|    4926.203716528163|\n",
      "+-------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_load = spark.read.csv('dsml-8/output/heath_group.csv',header=True)\n",
    "df_load.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ed1ca7e-6917-43f8-a1a7-add5354a7f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------------+\n",
      "|Hospital_code|Avg_admission_deposit|\n",
      "+-------------+---------------------+\n",
      "|            1|    5080.219089350352|\n",
      "+-------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('parquet').option('header',True).load('dsml-8/output/parquet/part-00000-a30133ef-e6b6-4a93-9351-8269dee70261-c000.snappy.parquet').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc5166-40b2-4b6f-b314-f2ffef6729b7",
   "metadata": {},
   "source": [
    "# SparkSQL \n",
    "### Creating Database and table using Temporary View or Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c97363-485e-465b-91ed-8f1d39dd6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_2 = 'id integer, order_date string, customer_id integer, order_status string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05ab99aa-4b24-4dee-946a-81a25930cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----------+---------------+\n",
      "| id|          order_date|customer_id|   order_status|\n",
      "+---+--------------------+-----------+---------------+\n",
      "|  2|2013-07-25 00:00:...|        256|PENDING_PAYMENT|\n",
      "|  3|2013-07-25 00:00:...|      12111|       COMPLETE|\n",
      "|  4|2013-07-25 00:00:...|       8827|         CLOSED|\n",
      "|  5|2013-07-25 00:00:...|      11318|       COMPLETE|\n",
      "|  6|2013-07-25 00:00:...|       7130|       COMPLETE|\n",
      "+---+--------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2= spark.read.format('csv').option('header','true').schema(schema_2).load('dsml-8/orders_1gb.csv')\n",
    "df2.show(5)\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b4b4b2c-d1e1-4316-a17d-9da613a998ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "new_df = df2.withColumnRenamed('order_status','status').withColumn('order_date',to_timestamp('order_date'))\n",
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "078c2423-ce1b-4744-8279-3a808af554b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 06:04:50,388 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2024-09-08 06:04:50,389 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2024-09-08 06:04:53,207 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "2024-09-08 06:04:53,208 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore tplbigdattrain@172.31.16.182\n",
      "2024-09-08 06:04:53,371 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "2024-09-08 06:04:53,377 ERROR metastore.RetryingHMSHandler: AlreadyExistsException(message:Database timepro_db already exists)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:925)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat com.sun.proxy.$Proxy37.create_database(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.createDatabase(HiveMetaStoreClient.java:727)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.invoke(RetryingMetaStoreClient.java:173)\n",
      "\tat com.sun.proxy.$Proxy38.createDatabase(Unknown Source)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createDatabase(Hive.java:427)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$createDatabase$1(HiveClientImpl.scala:334)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:291)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.createDatabase(HiveClientImpl.scala:332)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$createDatabase$1(HiveExternalCatalog.scala:193)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.createDatabase(HiveExternalCatalog.scala:193)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.createDatabase(ExternalCatalogWithListener.scala:47)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.createDatabase(SessionCatalog.scala:226)\n",
      "\tat org.apache.spark.sql.execution.command.CreateDatabaseCommand.run(ddl.scala:82)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:79)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating database\n",
    "spark.sql('create database if not exists timepro_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff84ab31-ef52-4c26-8c93-e6a3a503d140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 06:08:43,999 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2024-09-08 06:08:43,999 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2024-09-08 06:08:45,752 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "2024-09-08 06:08:45,752 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore tplbigdattrain@172.31.16.182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| namespace|\n",
      "+----------+\n",
      "|   default|\n",
      "|timepro_db|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show databases').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e7ad9-e199-4a22-969d-ad608143e5dd",
   "metadata": {},
   "source": [
    "spark.sql('use default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f5c5135a-bd3b-4111-8820-0cf2cba67119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----------+\n",
      "|database|    tableName|isTemporary|\n",
      "+--------+-------------+-----------+\n",
      "|        |patient_table|       true|\n",
      "|        |          xyz|       true|\n",
      "+--------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7b3375-8506-4f3c-bcf2-81419717b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 06:08:53,051 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('use timepro_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d062f874-4293-4690-84bc-4d994ce3a764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f00061-cb0f-4232-986e-42b32b7745a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.createOrReplaceTempView('orders1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a50b61fc-7612-4ba5-bbe5-052ddebdbca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |  orders1|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad8c587b-88e6-4362-b418-d8e217f514e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----------+---------------+\n",
      "| id|         order_date|customer_id|         status|\n",
      "+---+-------------------+-----------+---------------+\n",
      "|  2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|  3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|  4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|  5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "|  6|2013-07-25 00:00:00|       7130|       COMPLETE|\n",
      "+---+-------------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from orders1 limit 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99550c70-2800-45dd-b09d-887762903f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81dd4c0-0a78-4ea3-8470-a989f80ceffc",
   "metadata": {},
   "source": [
    "### describe Tablecre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f16998-7504-4b14-9fa4-565cac52370d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "177f7fed-7dbb-4d81-8e9a-266f83be2cb4",
   "metadata": {},
   "source": [
    "### Dropping created table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b09c8-c2e7-4789-9d0e-d015e699ef45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark 3",
   "language": "python",
   "name": "pyspark3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
